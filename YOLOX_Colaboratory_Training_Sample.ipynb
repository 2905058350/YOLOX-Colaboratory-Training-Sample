{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOX_Colaboratory_Training_Sample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KndWvALzfoG_"
      },
      "source": [
        "# YOLOX 依存パッケージインストール(YOLOX Dependent Package Install)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpviPxKHfh59"
      },
      "source": [
        "!git clone https://github.com/Megvii-BaseDetection/YOLOX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maY7_U3gLhQA"
      },
      "source": [
        "%cd YOLOX\n",
        "\n",
        "!pip install -U pip && pip install -r requirements.txt\n",
        "!pip install -v -e .  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYmfVRaKgyHB"
      },
      "source": [
        "# NVIDIA APEXインストール(NVIDIA APEX Install) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DSk59vpfvFA"
      },
      "source": [
        "# ToDo：将来的にColaboratoryのCUDA対応バージョンが変わった際にはインストールバージョンを変える必要あり\n",
        "# ToDo：If the CUDA compatible version of Colaboratory changes in the future, it is necessary to change the installation version\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gz_d-9if-Zc"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1t1Hb74iIZo"
      },
      "source": [
        "# PyCocoToolsインストール(PyCocoTools Install)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCje1A8mhtLy"
      },
      "source": [
        "!pip install cython\n",
        "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWp26peevulP"
      },
      "source": [
        "# データセットダウンロード(Download Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frzsMeeetO1y"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "use_sample_image = True\n",
        "\n",
        "if use_sample_image:\n",
        "    !git clone https://github.com/Kazuhito00/YOLOX-Colaboratory-Training-Sample.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC3Frlnzz5eC"
      },
      "source": [
        "# 学習/検証データ分割(Train/Validation split data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkp7yRJPv0_1"
      },
      "source": [
        "import os\n",
        "\n",
        "# 独自のデータを使用する場合は、パスを指定してください\n",
        "# Please fill in the path if you want to use your own data\n",
        "if use_sample_image:\n",
        "    dataset_directory = 'YOLOX-Colaboratory-Training-Sample/02.annotation_data'\n",
        "else:\n",
        "    dataset_directory = ''\n",
        "\n",
        "# 学習/検証データパス(train/validation data path)\n",
        "train_directory = './train'\n",
        "validation_directory = './validation'\n",
        "\n",
        "# 学習データ格納ディレクトリ作成(Create training data storage directory)\n",
        "os.makedirs(train_directory, exist_ok=True)\n",
        "# 検証データ格納ディレクトリ作成(Create verification data storage directory)\n",
        "os.makedirs(validation_directory, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJieAq9IywqQ"
      },
      "source": [
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# 学習データの割合(Percentage of training data)\n",
        "train_ratio = 0.8\n",
        "\n",
        "# コピー元ファイルリスト取得(Get copy source file list)\n",
        "annotation_list = sorted(glob.glob(dataset_directory + '/*.xml'))\n",
        "image_list = sorted(glob.glob(dataset_directory + '/*.jpg'))\n",
        "\n",
        "file_num = len(annotation_list)\n",
        "\n",
        "# インデックスシャッフル(shuffle)\n",
        "index_list = list(range(file_num - 1))\n",
        "random.shuffle(index_list)\n",
        "\n",
        "for count, index in enumerate(index_list):\n",
        "    if count < int(file_num * train_ratio):\n",
        "        # 学習用データ(Training Data)\n",
        "        shutil.copy2(annotation_list[index], train_directory)\n",
        "        shutil.copy2(image_list[index], train_directory)\n",
        "    else:\n",
        "        # 検証用データ(Validation Data)\n",
        "        shutil.copy2(annotation_list[index], validation_directory)\n",
        "        shutil.copy2(image_list[index], validation_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACKapHgx_d4Q"
      },
      "source": [
        "# Pascal VOC形式 を MS COCO形式へ変換(Convert Pascal VOC format to MS COCO format)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKGpaUik_c9m"
      },
      "source": [
        "!git clone https://github.com/Kazuhito00/voc2coco.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3xTEz30_kYp"
      },
      "source": [
        "!python voc2coco/voc2coco.py train train/train_annotations.json\n",
        "!python voc2coco/voc2coco.py validation validation/validation_annotations.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ9ytPB90pJP"
      },
      "source": [
        "# 学習データディレクトリ準備(Training data directory preparation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IccyvWRpDZGL"
      },
      "source": [
        "!mkdir dataset\n",
        "!mkdir dataset/images\n",
        "!mkdir dataset/images/train2017\n",
        "!mkdir dataset/images/val2017\n",
        "!mkdir dataset/annotations\n",
        "\n",
        "!cp -rf train/*.jpg dataset/images/train2017\n",
        "!cp -rf validation/*.jpg dataset/images/val2017\n",
        "!cp -rf train/train_annotations.json dataset/annotations\n",
        "!cp -rf validation/validation_annotations.json dataset/annotations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnUirebA1a__"
      },
      "source": [
        "# コンフィグコピー\n",
        "<!--\n",
        "![image](https://user-images.githubusercontent.com/37477845/135283504-254ea817-345e-4665-828a-4c6034645ed1.png)\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzlWZMuSPUly"
      },
      "source": [
        "if use_sample_image:\n",
        "    !cp /content/YOLOX-Colaboratory-Training-Sample/03.config/nano.py /content/YOLOX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVvBXq4e2ydb"
      },
      "source": [
        "# モデル訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykzClTsh1ZDA"
      },
      "source": [
        "%cd /content/YOLOX/\n",
        "!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_nano.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQgIQXww2x7-"
      },
      "source": [
        "!cp tools/train.py ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZDXBpaY22lN"
      },
      "source": [
        "!python train.py \\\n",
        "    -f nano.py \\\n",
        "    -d 1 \\\n",
        "    -b 16 \\\n",
        "    --fp16 \\\n",
        "    -o \\\n",
        "    -c yolox_nano.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmlvTpsheyQm"
      },
      "source": [
        "# 推論テスト(Inference test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3g0ZRUwMP8k"
      },
      "source": [
        "TEST_IMAGE_PATH = \"/content/YOLOX-Colaboratory-Training-Sample/01.image/000050.jpg\"\n",
        "MODEL_PATH = \"/content/YOLOX/YOLOX_outputs/nano/best_ckpt.pth\"\n",
        "\n",
        "!python tools/demo.py image \\\n",
        "    -f nano.py \\\n",
        "    -c {MODEL_PATH} \\\n",
        "    --path {TEST_IMAGE_PATH} \\\n",
        "    --conf 0.25 \\\n",
        "    --nms 0.45 \\\n",
        "    --tsize 640 \\\n",
        "    --save_result \\\n",
        "    --device gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL-oSdFrg0Pb"
      },
      "source": [
        "# from PIL import Image\n",
        "\n",
        "# OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/nano/vis_res/2021_09_29_17_46_56/000050.jpg\" \n",
        "# Image.open(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT2WBgo7jAvR"
      },
      "source": [
        "# ONNX出力(Export ONNX Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHpT0bQBhHzt"
      },
      "source": [
        "!python tools/export_onnx.py \\\n",
        "    --output-name yolox_nano.onnx \\\n",
        "    -n yolox-nano \\\n",
        "    -c {MODEL_PATH}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q501MZh_jkIv"
      },
      "source": [
        "!python demo/ONNXRuntime/onnx_inference.py \\\n",
        "    -m yolox_nano.onnx \\\n",
        "    -i {TEST_IMAGE_PATH} \\\n",
        "    -o ./ \\\n",
        "    -s 0.3 \\\n",
        "    --input_shape 416,416"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwcQysS_j_yp"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "OUTPUT_IMAGE_PATH = \"000050.jpg\" \n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKETcM79q3XD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}